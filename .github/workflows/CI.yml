### act --version
### > act version 0.2.69

name: Run tests
run-name: Run test with pytest
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    steps:
      - name: Run Bash Command and Set ENV
        run: |
          OUTPUT=$(id -u)
          echo "AIRFLOW_UID=$OUTPUT" >> $GITHUB_ENV

      - name: Checkout code
        uses: actions/checkout@v2
      
      - name: Create necessary directories
        run: mkdir -p ./dags ./logs ./plugins ./config

      - name: Docker compose build
        run: |
          docker compose build

      - name: Docker Init
        run: |
          docker compose up airflow-init

      - name: compose Up
        run: |
          docker compose up -d

      # - name: debug1
      #   if: always()
      #   run: |
      #     docker compose logs s3
      #     docker compose exec s3 printenv

      - name: Wait a bit
        run: sleep 10
            
      - name: Install and run pytest
        run: |
          docker compose exec airflow-scheduler python3 -m pip install pytest
          docker compose exec airflow-scheduler pytest -s --log-cli-level=INFO dags/tests

      - name: Display container logs if tests fail
        if: failure()
        run: |
          docker compose logs

      - name: Down
        if: always()
        run: |
          docker compose down --volumes